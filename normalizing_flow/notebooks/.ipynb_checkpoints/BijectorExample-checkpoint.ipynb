{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modified from Eric Jang's blog post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "import seaborn as sns\n",
    "sns.set(style=\"whitegrid\")\n",
    "tfd = tf.contrib.distributions\n",
    "tfb = tfd.bijectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.set_random_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=512\n",
    "DTYPE=tf.float32\n",
    "NP_DTYPE=np.float32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Target Density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET = 1\n",
    "if DATASET == 0:\n",
    "    mean = [0.4, 1]\n",
    "    A = np.array([[2, .3], [-1., 4]])\n",
    "    cov = A.T.dot(A)\n",
    "    print(mean)\n",
    "    print(cov)\n",
    "    X = np.random.multivariate_normal(mean, cov, 2000)\n",
    "    plt.scatter(X[:, 0], X[:, 1], s=10, color='red')\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(X.astype(NP_DTYPE))\n",
    "    dataset = dataset.repeat()\n",
    "    dataset = dataset.shuffle(buffer_size=X.shape[0])\n",
    "    dataset = dataset.prefetch(3 * batch_size)\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    data_iterator = dataset.make_one_shot_iterator()\n",
    "    x_samples = data_iterator.get_next()\n",
    "elif DATASET == 1:\n",
    "    x2_dist = tfd.Normal(loc=0., scale=4.)\n",
    "    x2_samples = x2_dist.sample(batch_size)\n",
    "    x1 = tfd.Normal(loc=.25 * tf.square(x2_samples),\n",
    "                    scale=tf.ones(batch_size, dtype=DTYPE))\n",
    "    x1_samples = x1.sample()\n",
    "    x_samples = tf.stack([x1_samples, x2_samples], axis=1)\n",
    "    np_samples = sess.run(x_samples)\n",
    "    plt.scatter(np_samples[:, 0], np_samples[:, 1], s=10)\n",
    "    plt.xlim([-5, 30])\n",
    "    plt.ylim([-10, 10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct Flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PReLU(tfb.Bijector):\n",
    "    def __init__(self, alpha=0.5, validate_args=False, name=\"p_relu\"):\n",
    "        super(PReLU, self).__init__(\n",
    "            forward_min_event_ndims=0,\n",
    "            validate_args=validate_args,\n",
    "            name=name)\n",
    "        self.alpha = alpha\n",
    "\n",
    "    def _forward(self, x):\n",
    "        return tf.where(tf.greater_equal(x, 0), x, self.alpha * x)\n",
    "\n",
    "    def _inverse(self, y):\n",
    "        return tf.where(tf.greater_equal(y, 0), y, 1. / self.alpha * y)\n",
    "\n",
    "    def _inverse_log_det_jacobian(self, y):\n",
    "        I = tf.ones_like(y)\n",
    "        J_inv = tf.where(tf.greater_equal(y, 0), I, 1.0 / self.alpha * I)\n",
    "        log_abs_det_J_inv = tf.log(tf.abs(J_inv))\n",
    "        return log_abs_det_J_inv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dist = tfd.MultivariateNormalDiag(loc=tf.zeros([2], DTYPE))\n",
    "d, r = 2, 2\n",
    "bijectors = []\n",
    "num_layers = 6\n",
    "for i in range(num_layers):\n",
    "    with tf.variable_scope('bijector_%d' % i):\n",
    "        V = tf.get_variable('V', [d, r], dtype=DTYPE)\n",
    "        shift = tf.get_variable('shift', [d], dtype=DTYPE)\n",
    "        L = tf.get_variable('L', [d*(d+1)/2], dtype=DTYPE)\n",
    "        bijectors.append(tfb.Affine(\n",
    "            scale_tril=tfd.fill_triangular(L),\n",
    "            scale_perturb_factor=V,\n",
    "            shift=shift,\n",
    "        ))\n",
    "        alpha = tf.abs(tf.get_variable('alpha', [], dtype=DTYPE))+.01\n",
    "        bijectors.append(PReLU(alpha=alpha))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_bijector = tfb.Chain(list(reversed(bijectors[:-1])),\n",
    "                         name='2d_mlp_bijector')\n",
    "dist = tfd.TransformedDistribution(\n",
    "    distribution=base_dist,\n",
    "    bijector=mlp_bijector\n",
    ")\n",
    "loss = -tf.reduce_mean(dist.log_prob(x_samples))\n",
    "train_op = tf.train.AdamOptimizer(1e-3).minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization (before training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualization\n",
    "x = base_dist.sample(512)\n",
    "samples = [x]\n",
    "names = [base_dist.name]\n",
    "for bijector in reversed(dist.bijector.bijectors):\n",
    "    x = bijector.forward(x)\n",
    "    samples.append(x)\n",
    "    names.append(bijector.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = sess.run(samples)\n",
    "f, arr = plt.subplots(1, len(results), figsize=(4 * (len(results)), 4))\n",
    "X0 = results[0]\n",
    "for i in range(len(results)):\n",
    "    X1 = results[i]\n",
    "    idx = np.logical_and(X0[:, 0] < 0, X0[:, 1] < 0)\n",
    "    arr[i].scatter(X1[idx, 0], X1[idx, 1], s=10, color='red')\n",
    "    idx = np.logical_and(X0[:, 0] > 0, X0[:, 1] < 0)\n",
    "    arr[i].scatter(X1[idx, 0], X1[idx, 1], s=10, color='green')\n",
    "    idx = np.logical_and(X0[:, 0] < 0, X0[:, 1] > 0)\n",
    "    arr[i].scatter(X1[idx, 0], X1[idx, 1], s=10, color='blue')\n",
    "    idx = np.logical_and(X0[:, 0] > 0, X0[:, 1] > 0)\n",
    "    arr[i].scatter(X1[idx, 0], X1[idx, 1], s=10, color='black')\n",
    "    arr[i].set_xlim([-2, 2])\n",
    "    arr[i].set_ylim([-2, 2])\n",
    "    arr[i].set_title(names[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimize Flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss = -tf.reduce_mean(dist.log_prob(x_samples))\n",
    "# train_op = tf.train.AdamOptimizer(1e-3).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_STEPS = int(1e5)\n",
    "global_step = []\n",
    "np_losses = []\n",
    "for i in range(NUM_STEPS):\n",
    "    _, np_loss = sess.run([train_op, loss])\n",
    "    if i % 1000 == 0:\n",
    "        global_step.append(i)\n",
    "        np_losses.append(np_loss)\n",
    "    if i % int(1e4) == 0:\n",
    "        print(i, np_loss)\n",
    "start = 10\n",
    "plt.plot(np_losses[start:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = sess.run(samples)\n",
    "f, arr = plt.subplots(1, len(results), figsize=(4 * (len(results)), 4))\n",
    "X0 = results[0]\n",
    "for i in range(len(results)):\n",
    "    X1 = results[i]\n",
    "    idx = np.logical_and(X0[:, 0] < 0, X0[:, 1] < 0)\n",
    "    arr[i].scatter(X1[idx, 0], X1[idx, 1], s=10, color='red')\n",
    "    idx = np.logical_and(X0[:, 0] > 0, X0[:, 1] < 0)\n",
    "    arr[i].scatter(X1[idx, 0], X1[idx, 1], s=10, color='green')\n",
    "    idx = np.logical_and(X0[:, 0] < 0, X0[:, 1] > 0)\n",
    "    arr[i].scatter(X1[idx, 0], X1[idx, 1], s=10, color='blue')\n",
    "    idx = np.logical_and(X0[:, 0] > 0, X0[:, 1] > 0)\n",
    "    arr[i].scatter(X1[idx, 0], X1[idx, 1], s=10, color='black')\n",
    "    arr[i].set_xlim([-5, 30])\n",
    "    arr[i].set_ylim([-10, 10])\n",
    "    arr[i].set_title(names[i])\n",
    "plt.savefig('toy2d_flow.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = sess.run(dist.sample(1000))\n",
    "plt.scatter(X1[:, 0], X1[:, 1], color='green', s=2)\n",
    "arr[i].set_xlim([-5, 30])\n",
    "arr[i].set_ylim([-10, 10])\n",
    "plt.savefig('toy2d_out.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np_losses[start:], c='red')\n",
    "plt.xlabel('Step')\n",
    "plt.ylabel('Negative Log-Likelihood')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
